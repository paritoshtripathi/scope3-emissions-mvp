# version: '3.8'

services:
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile.frontend
    ports:
      - "4200:80"  # Host port 4200 mapped to container port 80
    volumes:
      - ../frontend:/app
    environment:
      - NODE_ENV=production

  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile.backend
    ports:
      - "3000:3000"
    volumes:
      - ../backend:/app
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: scope3
      POSTGRES_HOST: postgres
    depends_on:
      - postgres

  ai-ml:
    build:
      context: ../ai-ml
      dockerfile: Dockerfile.ai-ml
    container_name: ai-ml
    ports:
      - "5000:5000"
    volumes:
      - ../ai-ml:/app/
      - ../ai-ml/models:/app/output    
    environment:
      USE_INFERENCE_API: "true"              # Set to "false" to use a local model
      LOCAL_MODEL_NAME: "distilbert-base-uncased"  # Specify local model name
      INFERENCE_API_URL: "https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct"
      HF_API_TOKEN: "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"
    depends_on:
      - weaviate

  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: scope3_weaviate
    ports:
      - 8080:8080
      - 50051:50051
    environment:
      - QUERY_DEFAULTS_LIMIT=20
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - DEFAULT_VECTORIZER_MODULE=text2vec-huggingface
      - ENABLE_MODULES=text2vec-huggingface
      - HUGGINGFACE_APIKEY="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"  # Replace with your actual API key
      - CLUSTER_HOSTNAME=node1
    volumes:
      - ../database/weaviate/data:/var/lib/weaviate
    restart: unless-stopped
   
  postgres:
    image: postgres:latest
    container_name: scope3_postgres
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: P@ssw0rd
      POSTGRES_DB: scope3
    ports:
      - "5432:5432"
    volumes:
      - ../database/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ../database/postgres/data:/var/lib/postgresql/data
    #postgres_data: /var/lib/postgresql/data

  neo4j:
    image: neo4j:latest
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - ../database/neo4j/data:/data
    environment:
      - NEO4J_AUTH=neo4j/securepassword

  rasa:
    build:
      context: ../rasa
      dockerfile: Dockerfile.rasa
    volumes:
      - ../rasa:/app
      - ../rasa/models:/app/models
      - ../rasa/logs:/app/logs
      - ../rasa/actions:/app/actions
      - ../rasa/config:/app/config
      - ../rasa/data:/app/data
    ports:
      - "5005:5005"
    environment:
      - PYTHONWARNINGS=ignore
      - SQLALCHEMY_WARN_20=0
      - SQLALCHEMY_SILENCE_UBER_WARNING=1
    
  actions:
    image: rasa/rasa-sdk:3.6.0
    volumes:
      - ../rasa/actions:/app/actions
    ports:
      - "5055:5055"

  data-insight-agent:
    build:
      context: ../ai-ml/agents/data_insight_agent
    ports:
      - "5001:5000"

  narrative-agent:
    build:
      context: ../ai-ml/agents/narrative_agent
    ports:
      - "5002:5000"